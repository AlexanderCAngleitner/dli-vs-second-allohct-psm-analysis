{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a85a6-0ccf-4bcc-b5a8-62d6b0c2c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.utils import median_survival_times\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"your_data.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "time_col = \"Time\"\n",
    "event_col = \"Survival\"                  # 1=death, 0=censored\n",
    "group_col = \"DLI vs 2nd allo-HCT\"       # 0=DLI, 1=2nd allo-HCT\n",
    "df = df.dropna(subset=[time_col, event_col, group_col])\n",
    "df[group_col] = df[group_col].map({0: \"Therapeutic DLI\", 1: \"2nd allo-HCT\"})\n",
    "\n",
    "# Setup\n",
    "colors = {\"2nd allo-HCT\": \"#1f77b4\", \"Therapeutic DLI\": \"#d62728\"}\n",
    "time_bins = np.arange(0, int(np.ceil(df[time_col].max())) + 1, 1)\n",
    "risk_table = pd.DataFrame(index=time_bins)\n",
    "\n",
    "# Figure setup\n",
    "fig, (ax_km, ax_table) = plt.subplots(2, 1, figsize=(10, 8),\n",
    "                                      gridspec_kw={\"height_ratios\": [4, 1]})\n",
    "kmf = KaplanMeierFitter()\n",
    "median_dict, ci_dict = {}, {}\n",
    "\n",
    "# New: Plateau container\n",
    "plateau_dict = {}   # {grp: (plateau_height, last_event_time)}\n",
    "\n",
    "# Kaplan–Meier curves + risk table + plateau\n",
    "for grp in [\"2nd allo-HCT\", \"Therapeutic DLI\"]:\n",
    "    sub = df[df[group_col] == grp].copy()\n",
    "    T = sub[time_col].astype(float)\n",
    "    E = sub[event_col].astype(int)\n",
    "\n",
    "    kmf.fit(T, E, label=f\"{grp} (n = {len(sub)})\")\n",
    "    kmf.plot(ax=ax_km, ci_show=True, ci_alpha=0.2, color=colors[grp], linewidth=2)\n",
    "\n",
    "    # Median OS + CI\n",
    "    med = kmf.median_survival_time_\n",
    "    ci_df = median_survival_times(kmf.confidence_interval_)\n",
    "    lo, hi = ci_df.iloc[0]\n",
    "    median_dict[grp] = med\n",
    "    ci_dict[grp] = (lo, hi)\n",
    "\n",
    "    # Number at risk (simply counted per full year step)\n",
    "    at_risk = [int(np.sum(T >= t)) for t in time_bins]\n",
    "    risk_table[grp] = at_risk\n",
    "\n",
    "    # -------- Plateau calculation (NEW) ----------\n",
    "    # last time point with at least one observed event\n",
    "    try:\n",
    "        last_event_time = kmf.event_table.query(\"observed > 0\").index.max()\n",
    "    except ValueError:\n",
    "        # If no events in the group (extremely rare) -> plateau = 1.0, last_event_time = 0\n",
    "        last_event_time = 0.0\n",
    "\n",
    "    # Plateau height = last KM value (after the last event the curve remains flat)\n",
    "    plateau_height = float(kmf.survival_function_.iloc[-1, 0])\n",
    "\n",
    "    plateau_dict[grp] = (plateau_height, float(last_event_time) if last_event_time is not None else np.nan)\n",
    "\n",
    "    # Visual marker: horizontal line from last event until max time of the group\n",
    "    xmax = float(T.max())\n",
    "    if np.isfinite(last_event_time) and xmax > last_event_time:\n",
    "        ax_km.hlines(plateau_height, xmin=last_event_time, xmax=xmax,\n",
    "                     colors=colors[grp], linestyles=\":\", linewidth=1.5)\n",
    "        ax_km.scatter([last_event_time], [plateau_height], s=30, color=colors[grp], zorder=3)\n",
    "\n",
    "# Log-rank test\n",
    "g1, g2 = [df[df[group_col] == g] for g in [\"2nd allo-HCT\", \"Therapeutic DLI\"]]\n",
    "p = logrank_test(g1[time_col], g2[time_col],\n",
    "                 event_observed_A=g1[event_col], event_observed_B=g2[event_col]).p_value\n",
    "ax_km.text(0.95, 0.05, f\"Log-rank p = {p:.4f}\", transform=ax_km.transAxes,\n",
    "           ha=\"right\", va=\"bottom\", fontsize=13,\n",
    "           bbox=dict(facecolor=\"white\", edgecolor=\"grey\", alpha=0.8))\n",
    "\n",
    "# Styling\n",
    "ax_km.set_xlabel(\"Time from intervention (years)\", fontsize=14)\n",
    "ax_km.set_ylabel(\"Overall survival probability\", fontsize=14)\n",
    "ax_km.set_ylim(0, 1)\n",
    "ax_km.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "ax_km.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "ax_km.tick_params(labelsize=12)\n",
    "ax_km.legend(title=\"Treatment group\", frameon=False, fontsize=12, title_fontsize=13)\n",
    "\n",
    "# Number at risk table\n",
    "ax_table.axis(\"off\")\n",
    "col_labels = [str(t) for t in risk_table.index]\n",
    "table_data = [risk_table[\"2nd allo-HCT\"].tolist(),\n",
    "              risk_table[\"Therapeutic DLI\"].tolist()]\n",
    "row_labels = [\"2nd allo-HCT\", \"Therapeutic DLI\"]\n",
    "ax_table.table(cellText=table_data, rowLabels=row_labels, colLabels=col_labels,\n",
    "               loc=\"center\", cellLoc=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Descriptive statistics per group + plateau output\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n Descriptive statistics:\")\n",
    "for grp in [\"2nd allo-HCT\", \"Therapeutic DLI\"]:\n",
    "    sub = df[df[group_col] == grp]\n",
    "    n_total = len(sub)\n",
    "    n_events = int(sub[event_col].sum())\n",
    "    n_censored = int(n_total - n_events)\n",
    "    med_os = median_dict[grp]\n",
    "    ci_lo, ci_hi = ci_dict[grp]\n",
    "    plateau_height, last_evt = plateau_dict[grp]\n",
    "\n",
    "    print(f\"\\n {grp}\")\n",
    "    print(f\"   - Number of patients      : {n_total}\")\n",
    "    print(f\"   - Events (deaths)         : {n_events}\")\n",
    "    print(f\"   - Censored                : {n_censored}\")\n",
    "    print(f\"   - Median OS               : {med_os:.2f} years \"\n",
    "          f\"(95% CI: {ci_lo:.2f} – {ci_hi:.2f})\")\n",
    "    if np.isnan(last_evt):\n",
    "        print(f\"   - Plateau                 : {plateau_height:.3f} (no events observed)\")\n",
    "    else:\n",
    "        print(f\"   - Plateau                 : {plateau_height:.3f} (after last event at t={last_evt:.2f} years)\")\n",
    "\n",
    "# Save figure\n",
    "out_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"KM_OS_DLI_vs_2nd_allo_with_risk_plateau.tiff\")\n",
    "fig.savefig(out_path, dpi=600, format=\"tiff\", bbox_inches=\"tight\")\n",
    "print(f\"\\n Figure saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd41d8-690c-4ff4-8808-2494f6b8320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.exceptions import ConvergenceError\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(\"Cox_10_10.xlsx\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Time and event variables\n",
    "time_col = \"Time\"\n",
    "event_col = \"Survival\"\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Variables to be excluded from the analysis\n",
    "excluded_vars = [time_col, event_col, 'CR']\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in excluded_vars:\n",
    "        temp_df = df[[time_col, event_col, col]].copy()\n",
    "        cph = CoxPHFitter()\n",
    "        try:\n",
    "            cph.fit(temp_df, duration_col=time_col, event_col=event_col)\n",
    "            summary = cph.summary.loc[col]\n",
    "            results.append({\n",
    "                \"Variable\": col,\n",
    "                \"Hazard Ratio\": summary[\"exp(coef)\"],\n",
    "                \"95% CI Lower\": summary[\"exp(coef) lower 95%\"],\n",
    "                \"95% CI Upper\": summary[\"exp(coef) upper 95%\"],\n",
    "                \"p-value\": summary[\"p\"]\n",
    "            })\n",
    "        except ConvergenceError:\n",
    "            print(f\" Convergence issue with '{col}' – skipped.\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error with '{col}': {e}\")\n",
    "\n",
    "# Display results sorted by p-value\n",
    "cox_results = pd.DataFrame(results).sort_values(by=\"p-value\")\n",
    "print(\"\\n Univariate Cox regression results:\\n\")\n",
    "if not cox_results.empty:\n",
    "    print(cox_results.to_string(index=False, float_format=\"%.3f\"))\n",
    "else:\n",
    "    print(\" No valid models were computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb504039-c4bb-418a-8f8a-df031daee707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "#  Propensity Score Matching – Model C (ECOG + Time-to-Relapse)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1)  File and constants\n",
    "# ---------------------------------------------------------------\n",
    "MODEL_NAME = \"C\"                         # << control here consistently\n",
    "FILE        = \"your_data.xlsx\"           # adjust path if necessary\n",
    "TREAT_COL   = \"Treatment\"                # 0 = DLI, 1 = 2nd allo-HCT\n",
    "MATCH_VARS  = [\"ECOG\", \"Time to Relapse\"]  # Model C\n",
    "CALIPER_F   = 0.2                        # 0.2 × SD(LogitPS)\n",
    "\n",
    "# (optional) If you want to save outcomes as well:\n",
    "# Enter your actual outcome columns here, or leave the list empty.\n",
    "OUTCOME_VARS = [\"Time\", \"Survival\"]      # or [] if not available\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2)  Load data, keep only complete rows for PS model\n",
    "# ---------------------------------------------------------------\n",
    "df0 = pd.read_excel(FILE)\n",
    "df0.columns = df0.columns.str.strip()\n",
    "\n",
    "df  = df0[[TREAT_COL] + MATCH_VARS].dropna().copy()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3)  Propensity score model (logistic regression)\n",
    "# ---------------------------------------------------------------\n",
    "X_std = StandardScaler().fit_transform(df[MATCH_VARS])\n",
    "y     = df[TREAT_COL]\n",
    "\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "logit.fit(X_std, y)\n",
    "\n",
    "df[\"pscore\"]      = logit.predict_proba(X_std)[:, 1]\n",
    "df[\"logit_score\"] = logit.decision_function(X_std)\n",
    "caliper           = CALIPER_F * df[\"logit_score\"].std()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4)  1:1 matching (nearest neighbor, without replacement)\n",
    "# ---------------------------------------------------------------\n",
    "treated  = df[df[TREAT_COL] == 1]\n",
    "control  = df[df[TREAT_COL] == 0]\n",
    "\n",
    "dist = pairwise_distances(\n",
    "    treated[\"logit_score\"].values.reshape(-1,1),\n",
    "    control[\"logit_score\"].values.reshape(-1,1)\n",
    ")\n",
    "\n",
    "t_idx, c_idx = [], []\n",
    "for i, row in enumerate(dist):\n",
    "    j = row.argmin()\n",
    "    if row[j] <= caliper and control.index[j] not in c_idx:\n",
    "        t_idx.append(treated.index[i])\n",
    "        c_idx.append(control.index[j])\n",
    "\n",
    "matched = df.loc[t_idx + c_idx].copy()\n",
    "matched[\"pair_id\"] = np.repeat(range(len(t_idx)), 2)\n",
    "\n",
    "print(f\"\\n  Model {MODEL_NAME}: {len(t_idx)} pairs matched ({len(matched)} patients)\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5)  Balance (Standardized Mean Difference)\n",
    "# ---------------------------------------------------------------\n",
    "def smd(a, b): \n",
    "    return (a.mean() - b.mean()) / np.sqrt(0.5*(a.var() + b.var()))\n",
    "\n",
    "rows = []\n",
    "for v in MATCH_VARS:\n",
    "    before = smd(treated[v], control[v])\n",
    "    after  = smd(matched[matched[TREAT_COL]==1][v],\n",
    "                 matched[matched[TREAT_COL]==0][v])\n",
    "    rows.append([v, round(before,3), round(after,3)])\n",
    "\n",
    "bal = pd.DataFrame(rows, columns=[\"Variable\",\"SMD_before\",\"SMD_after\"])\n",
    "print(\"\\nSMD (|SMD|<0.1 = good balance):\")\n",
    "print(bal)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6)  Love plot\n",
    "# ---------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, max(2, len(MATCH_VARS)*0.45)))\n",
    "ax.hlines(y=bal[\"Variable\"], xmin=bal[\"SMD_before\"], xmax=bal[\"SMD_after\"])\n",
    "ax.scatter(bal[\"SMD_before\"], bal[\"Variable\"], label=\"Before\", marker=\"o\")\n",
    "ax.scatter(bal[\"SMD_after\"],  bal[\"Variable\"], label=\"After\",  marker=\"s\")\n",
    "ax.axvline(0,    ls=\"--\", color=\"grey\")\n",
    "ax.axvline(0.1,  ls=\":\",  color=\"grey\")\n",
    "ax.axvline(-0.1, ls=\":\",  color=\"grey\")\n",
    "ax.set_xlabel(\"Standardized Mean Difference\")\n",
    "ax.set_title(f\"Covariate Balance – Model {MODEL_NAME}\")\n",
    "ax.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 7)  Save matched dataset (with optional outcomes)\n",
    "# ---------------------------------------------------------------\n",
    "out_base = f\"matched_model_{MODEL_NAME}\"\n",
    "out_path = Path(f\"{out_base}.xlsx\")\n",
    "\n",
    "matched.to_excel(out_path, index=False)\n",
    "print(f\"\\n  Matched dataset saved: {out_path.resolve()}\")\n",
    "\n",
    "# Optional: save full dataset including outcomes\n",
    "if OUTCOME_VARS:\n",
    "    # Merge by index, since 'matched' retains the original indices\n",
    "    keep_cols = [TREAT_COL] + MATCH_VARS + OUTCOME_VARS\n",
    "    missing = [c for c in OUTCOME_VARS if c not in df0.columns]\n",
    "    if missing:\n",
    "        print(f\"  OUTCOME_VARS not found in source file: {missing}\")\n",
    "    matched_full = matched.join(df0[OUTCOME_VARS], how=\"left\")\n",
    "    out_full_path = Path(f\"{out_base}_full.xlsx\")\n",
    "    matched_full.to_excel(out_full_path, index=False)\n",
    "    print(f\"  Full matched dataset saved: {out_full_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8caf2b-d145-436f-a29c-265132759a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from lifelines.utils import median_survival_times\n",
    "import os\n",
    "\n",
    "# ── 1) Load matched dataset ─────────────────────────────────────\n",
    "df = pd.read_excel(\"matched_model_C_full.xlsx\")\n",
    "TREAT, TIME, EVENT = \"Treatment\", \"Time\", \"Survival\"\n",
    "LABELS  = {0: \"Therapeutic DLI\", 1: \"2nd allo-HCT\"}\n",
    "COLORS  = {0: \"blue\", 1: \"darkorange\"}\n",
    "\n",
    "# ── 2) Plot setup ───────────────────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "kmf_list = []\n",
    "\n",
    "for g in [0, 1]:\n",
    "    mask = df[TREAT] == g\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df.loc[mask, TIME], df.loc[mask, EVENT], label=LABELS[g])\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True,\n",
    "                               linewidth=2, color=COLORS[g])\n",
    "    kmf_list.append(kmf)\n",
    "\n",
    "    # Median OS + 95% CI\n",
    "    median_ci = median_survival_times(kmf.confidence_interval_)\n",
    "    median    = kmf.median_survival_time_\n",
    "    ci_lower  = median_ci.iloc[0, 0]\n",
    "    ci_upper  = median_ci.iloc[0, 1]\n",
    "\n",
    "    # Number of events and censored\n",
    "    n_total = mask.sum()\n",
    "    n_event = df.loc[mask, EVENT].sum()\n",
    "    n_censored = n_total - n_event\n",
    "\n",
    "    print(f\"{LABELS[g]}:\")\n",
    "    print(f\"  → Median OS = {median:.2f} years (95% CI: {ci_lower:.2f} – {ci_upper:.2f})\")\n",
    "    print(f\"  → Events: {int(n_event)}   |   Censored: {int(n_censored)}   |   Total: {n_total}\\n\")\n",
    "\n",
    "# ── 3) Number at risk ───────────────────────────────────────────\n",
    "add_at_risk_counts(*kmf_list, ax=ax)\n",
    "\n",
    "# ── 4) Log-rank test & annotation ───────────────────────────────\n",
    "mask0 = df[TREAT] == 0\n",
    "mask1 = df[TREAT] == 1\n",
    "p_val = logrank_test(df.loc[mask0, TIME], df.loc[mask1, TIME],\n",
    "                     df.loc[mask0, EVENT], df.loc[mask1, EVENT]).p_value\n",
    "\n",
    "ax.text(0.95, 0.03, f\"Log-rank p = {p_val:.3f}\", transform=ax.transAxes,\n",
    "        ha='right', va='bottom', fontsize=11)\n",
    "\n",
    "# ── 5) Layout ───────────────────────────────────────────────────\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_xlabel(\"Time (years)\", fontsize=12)\n",
    "ax.set_ylabel(\"Overall Survival\", fontsize=12)\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ── 6) Save figure ──────────────────────────────────────────────\n",
    "out_path = os.path.expanduser(\"~/Desktop/PSM_OS_DLI_vs_2nd_allo_FINAL.tiff\")\n",
    "fig.savefig(out_path, dpi=600, format=\"tiff\")\n",
    "print(f\" Kaplan-Meier curve saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2e052-8fd4-486e-98ce-98b069661044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 0) Parameters\n",
    "# -----------------------------------------------------------\n",
    "# Excel file is located in the same folder as this script/notebook\n",
    "excel_path = \"your_data.xlsx\"   # ← no path needed\n",
    "t_limit    = 2.0       # RMST up to 2 years\n",
    "out_file   = \"CIF_RRM_NRM.tiff\"     # 600-dpi TIFF\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1) Load and prepare data\n",
    "# -----------------------------------------------------------\n",
    "df = pd.read_excel(excel_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "df[\"Group\"] = df[\"Treatment\"].map({0: \"DLI\", 1: \"2nd allo-HCT\"})\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) Helper function: CIF per group and event type\n",
    "# -----------------------------------------------------------\n",
    "def compute_cif(data, event_code, group_col,\n",
    "                time_col=\"Time\", status_col=\"Mortality\"):\n",
    "    res = {}\n",
    "    for grp in data[group_col].unique():\n",
    "        sub = (data[data[group_col] == grp]\n",
    "               .copy()\n",
    "               .sort_values(time_col))\n",
    "        times, status = sub[time_col].values, sub[status_col].values\n",
    "        uniq_t = np.unique(times)\n",
    "\n",
    "        cif_vals, surv_vals = [], []\n",
    "        cum_hazard, cif = 0.0, 0.0\n",
    "        for t in uniq_t:\n",
    "            at_risk          = (times >= t).sum()\n",
    "            all_events       = ((times == t) & (status != 0)).sum()\n",
    "            events_of_type   = ((times == t) & (status == event_code)).sum()\n",
    "\n",
    "            hazard      = all_events / at_risk\n",
    "            sub_hazard  = events_of_type / at_risk\n",
    "            cif        += sub_hazard * np.exp(-cum_hazard)\n",
    "            cum_hazard += hazard\n",
    "\n",
    "            cif_vals.append(cif)\n",
    "            surv_vals.append(np.exp(-cum_hazard))\n",
    "\n",
    "        res[grp] = (uniq_t, np.array(cif_vals), np.array(surv_vals))\n",
    "    return res\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) Compute CIF & survival functions\n",
    "# -----------------------------------------------------------\n",
    "cif_rrm = compute_cif(df, event_code=1, group_col=\"Group\")\n",
    "cif_nrm = compute_cif(df, event_code=2, group_col=\"Group\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) Compute RMST up to t_limit\n",
    "# -----------------------------------------------------------\n",
    "def rmst(t, surv, t_star):\n",
    "    t = np.concatenate([[0], t, [t_star]])\n",
    "    s = np.concatenate([[1], surv, [surv[-1]]])\n",
    "    mask = t <= t_star\n",
    "    return np.trapz(s[mask], t[mask])\n",
    "\n",
    "rmst_dict = {}\n",
    "for grp in cif_rrm:\n",
    "    t = cif_rrm[grp][0]\n",
    "    surv_total = 1.0 - (cif_rrm[grp][1] + cif_nrm[grp][1])\n",
    "    rmst_dict[grp] = rmst(t, surv_total, t_limit)\n",
    "\n",
    "print(f\"\\n RMST up to {t_limit} years\")\n",
    "for g, v in rmst_dict.items():\n",
    "    print(f\"   {g:12s}: {v:.2f} years\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) 1- and 2-year incidences from CIF\n",
    "# -----------------------------------------------------------\n",
    "def incidence(cif_tuple, year):\n",
    "    t, cif_vals = cif_tuple[0], cif_tuple[1]\n",
    "    return np.interp(year, t, cif_vals, left=0, right=cif_vals[-1])\n",
    "\n",
    "for year in [1, 2]:\n",
    "    print(f\"\\ Incidence at {year} year(s)\")\n",
    "    for grp in df[\"Group\"].unique():\n",
    "        print(f\"   {grp:12s}: \"\n",
    "              f\"RRM {incidence(cif_rrm[grp], year):.2%}  |  \"\n",
    "              f\"NRM {incidence(cif_nrm[grp], year):.2%}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) Plot & export to TIFF\n",
    "# -----------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for grp in cif_rrm:\n",
    "    t, rrm, _ = cif_rrm[grp]\n",
    "    _, nrm, _ = cif_nrm[grp]\n",
    "    plt.step(t, rrm, where=\"post\", label=f\"{grp} – RRM\", linewidth=2)\n",
    "    plt.step(t, nrm, where=\"post\", label=f\"{grp} – NRM\",\n",
    "             linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.xlabel(\"Time (years)\")\n",
    "plt.ylabel(\"Cumulative incidence\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_file, dpi=600, format=\"tiff\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Figure saved to: {os.path.abspath(out_file)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
